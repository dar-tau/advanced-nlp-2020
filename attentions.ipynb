{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FeGNJuzX5lwN"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pRztYi7T5lwW"
   },
   "outputs": [],
   "source": [
    "universityStorage = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:51:46.129829Z",
     "start_time": "2020-08-11T18:51:46.127294Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wnuOEkE85lwZ",
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "guy_folder = \"/vol/scratch/guy\" if universityStorage else \"/content\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snTq16Ru5lwd"
   },
   "source": [
    "### pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T07:55:13.714311Z",
     "start_time": "2020-08-10T07:54:15.569196Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "f6nEbhZs5lwe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (3.3.1)\n",
      "Requirement already satisfied: seaborn in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: pandas in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: tqdm in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (4.46.0)\n",
      "Requirement already satisfied: tensorboard in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (3.13.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (1.20.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (1.31.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (46.4.0.post20200518)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib seaborn pandas tqdm tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hPNjtF95lxA"
   },
   "source": [
    "### PyTorch + Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "UsNuEmiI5lxB",
    "outputId": "b66d4df4-b45a-4b82-dad1-0d449d98788b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/specific/scratches/scratch/guy\n",
      "mkdir: cannot create directory 'torch-transformers-cache': File exists\n"
     ]
    }
   ],
   "source": [
    "%cd {guy_folder}\n",
    "!mkdir torch-transformers-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T07:59:21.635288Z",
     "start_time": "2020-08-10T07:58:42.530263Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "H144hSbF5lxD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/specific/scratches/scratch/guy\n",
      "mkdir: cannot create directory 'torch-transformers-cache': File exists\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.4.0+cu100 in ./miniconda/lib/python3.8/site-packages (1.4.0+cu100)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/specific/scratches/scratch/guy/torch-transformers-cache\n",
      "Cloning into 'transformers'...\n",
      "remote: Enumerating objects: 23, done.\u001b[K\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 38349 (delta 9), reused 9 (delta 2), pack-reused 38326\u001b[K\n",
      "Receiving objects: 100% (38349/38349), 27.73 MiB | 5.96 MiB/s, done.\n",
      "Resolving deltas: 100% (26573/26573), done.\n",
      "Checking connectivity... done.\n",
      "Checking out files: 100% (1014/1014), done.\n",
      "Processing ./transformers\n",
      "Requirement already satisfied: numpy in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from transformers==3.0.2) (1.19.1)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "  Using cached tokenizers-0.8.1rc2-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: requests in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from transformers==3.0.2) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from transformers==3.0.2) (4.46.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2020.7.14-cp38-cp38-manylinux2010_x86_64.whl (672 kB)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\n",
      "Processing /specific/a/home/cc/students/cs/dar/.cache/pip/wheels/7b/78/f4/27d43a65043e1b75dbddaa421b573eddc67e712be4b1c80677/sacremoses-0.0.43-py3-none-any.whl\n",
      "Requirement already satisfied: six in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from packaging->transformers==3.0.2) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests->transformers==3.0.2) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests->transformers==3.0.2) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests->transformers==3.0.2) (2020.6.20)\n",
      "Collecting joblib\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting click\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-3.0.2-py3-none-any.whl size=858593 sha256=e3adb78ed010b7923e7ac8c317f2292dd00723dfd1b01fb5982c131f0fa6684e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vlseae09/wheels/b2/c5/c3/84a04d19f1e166956bee9fa37a94f05956fd042edc35567761\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, packaging, filelock, regex, sentencepiece, joblib, click, sacremoses, transformers\n",
      "Successfully installed click-7.1.2 filelock-3.0.12 joblib-0.16.0 packaging-20.4 regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting nlp\n",
      "  Using cached nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
      "Processing /specific/a/home/cc/students/cs/dar/.cache/pip/wheels/93/7f/7d/78ec535a4340ef2696aad8b17fe8bb063d56301bd62881b069/dill-0.3.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: numpy in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from nlp) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from nlp) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from nlp) (4.46.0)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-2.0.0-cp38-cp38-manylinux2010_x86_64.whl (243 kB)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from nlp) (3.0.12)\n",
      "Collecting pyarrow>=0.16.0\n",
      "  Using cached pyarrow-1.0.0-cp38-cp38-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from nlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests>=2.19.0->nlp) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests>=2.19.0->nlp) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from requests>=2.19.0->nlp) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from pandas->nlp) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from pandas->nlp) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.14.0)\n",
      "Installing collected packages: dill, xxhash, pyarrow, nlp\n",
      "Successfully installed dill-0.3.2 nlp-0.4.0 pyarrow-1.0.0 xxhash-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/specific/scratches/scratch/guy\n"
     ]
    }
   ],
   "source": [
    "%cd {guy_folder}\n",
    "!mkdir datasets\n",
    "!mkdir torch-transformers-cache\n",
    "\n",
    "%pip install --no-cache-dir torch==1.4.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "%cd {guy_folder}/torch-transformers-cache/\n",
    "!git clone https://github.com/huggingface/transformers.git\n",
    "%pip install ./transformers\n",
    "%pip install -U nlp\n",
    "\n",
    "%cd {guy_folder}\n",
    "## Not working!!!\n",
    "!setenv TRANSFORMERS_CACHE /vol/scratch/guy/torch-transformers-cache\n",
    "!setenv CUDA_VISIBLE_DEVICES 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0grNoXN5lxJ"
   },
   "source": [
    "#### Update Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Q_l4MeVn5lxK",
    "outputId": "d4b622c8-8fa6-40c8-aabc-c7fd94ba1f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/specific/scratches/scratch/guy/torch-transformers-cache/transformers\n",
      "Already up-to-date.\n",
      "Obtaining file:///specific/scratches/scratch/guy/torch-transformers-cache/transformers\n",
      "Requirement already satisfied: numpy in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (1.19.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (0.8.1rc2)\n",
      "Requirement already satisfied: packaging in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (20.4)\n",
      "Requirement already satisfied: filelock in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (3.0.12)\n",
      "Requirement already satisfied: requests in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (4.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (2020.7.14)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from transformers==3.0.2) (0.0.43)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
      "Requirement already satisfied: six in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (1.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: click in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
      "Requirement already satisfied: joblib in /specific/scratches/scratch/guy/miniconda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (0.16.0)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 3.0.2\n",
      "    Uninstalling transformers-3.0.2:\n",
      "      Successfully uninstalled transformers-3.0.2\n",
      "  Running setup.py develop for transformers\n",
      "Successfully installed transformers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd {guy_folder}/torch-transformers-cache/transformers\n",
    "!git pull\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4KL7QM05lxN"
   },
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T08:03:33.452119Z",
     "start_time": "2020-08-10T07:59:58.327675Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Ga-Z7SLJ5lxN",
    "outputId": "502b30d6-1b0b-4c3b-bea2-5749649d704c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/specific/scratches/scratch/guy/datasets\n",
      "--2020-08-16 12:54:47--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: 'aclImdb_v1.tar.gz'\n",
      "\n",
      "100%[======================================>] 84,125,825  1.04MB/s   in 97s    \n",
      "\n",
      "2020-08-16 12:56:25 (847 KB/s) - 'aclImdb_v1.tar.gz' saved [84125825/84125825]\n",
      "\n",
      "/specific/scratches/scratch/guy\n"
     ]
    }
   ],
   "source": [
    "%cd {guy_folder}/datasets\n",
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf acl*.tar.gz\n",
    "%cd {guy_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkN-nMU95lxP"
   },
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:51:48.838700Z",
     "start_time": "2020-08-11T18:51:46.139543Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3uSn0h9S5lxQ",
    "init_cell": true,
    "outputId": "f31d917a-65bf-43ed-a604-07c2d30b18d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/specific/scratches/scratch/guy/datasets\n"
     ]
    }
   ],
   "source": [
    "cache_dir = guy_folder + \"/torch-transformers-cache/\"\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re, pdb\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "%cd {guy_folder}/datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWAn-iNH5lxS"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "B3fXBkNJ5lxT",
    "outputId": "93124ced-3716-428a-aa32-96a8a0d98a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/specific/scratches/scratch/guy\n",
      "mkdir: cannot create directory 'datasets': File exists\n"
     ]
    }
   ],
   "source": [
    "%cd {guy_folder}\n",
    "!mkdir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:52:22.072850Z",
     "start_time": "2020-08-11T18:51:48.841009Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Xzr6EAIq5lxa",
    "init_cell": true,
    "outputId": "ba720fb1-96d5-43c1-eb05-1730eaa8bd3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75000/75000 [02:32<00:00, 491.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "sentences = []\n",
    "target = []\n",
    "path =  guy_folder + '/datasets/aclImdb/train/**/*.txt' \n",
    "files = glob.glob(path)\n",
    "for name in tqdm(files):\n",
    "    with open(name) as f:\n",
    "        target+=[int('pos' in name)] # Classical quick & dirty\n",
    "        sentences += [l for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmBVLY7F5lxd"
   },
   "source": [
    "## Transformers Initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vOYa5sl5lxd"
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T08:04:21.720127Z",
     "start_time": "2020-08-10T08:04:21.716032Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0bSZ7Ivs5lxe"
   },
   "outputs": [],
   "source": [
    "padding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:52:42.105495Z",
     "start_time": "2020-08-11T18:52:22.075141Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3yfJ8kCO5lxg",
    "init_cell": true,
    "outputId": "11f6307b-477f-4c3e-a2ef-b6727c78b91e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if ('padding' not in globals()) and ('padding' not in locals()):\n",
    "    padding = False\n",
    "from transformers import BertTokenizerFast, GPT2TokenizerFast, RobertaTokenizerFast\n",
    "device = 'cpu'\n",
    "bertTokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', output_attentions = True,  cache_dir = cache_dir)\n",
    "bertModel = AutoModel.from_pretrained('bert-base-uncased', output_attentions = True, cache_dir = cache_dir)\n",
    "\n",
    "robertaTokenizer = RobertaTokenizerFast.from_pretrained('roberta-base',   output_attentions = True, cache_dir = cache_dir)\n",
    "robertaModel = AutoModel.from_pretrained('roberta-base',   output_attentions = True, cache_dir = cache_dir)\n",
    "\n",
    "gptModel = AutoModel.from_pretrained('gpt2',   output_attentions = True, cache_dir = cache_dir)\n",
    "\n",
    "if padding:\n",
    "    gptTokenizer = GPT2TokenizerFast.from_pretrained('gpt2',   output_attentions = True, cache_dir = cache_dir, pad_token = '<PAD>')    \n",
    "else:\n",
    "    gptTokenizer = GPT2TokenizerFast.from_pretrained('gpt2',   output_attentions = True, cache_dir = cache_dir)#, pad_token = '<PAD>')\n",
    "\n",
    "bertModel=bertModel.to(device)\n",
    "gptModel=gptModel.to(device)\n",
    "if padding:\n",
    "    gptModel.resize_token_embeddings(len(gptTokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:52:42.121351Z",
     "start_time": "2020-08-11T18:52:42.108498Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jaVhpCY_5lxj",
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def _getAttentionsReshaped(outputs, wordsToTokens = None, layerwise = False, reshape = True):\n",
    "    attentions_ = outputs[-1]#.attentions # (n_layers, batch, n_heads, N, N) TODO: Verify!\n",
    "    attentions = torch.stack(attentions_).permute(0, 2, 1, 3, 4)\n",
    "    if wordsToTokens is not None:\n",
    "        shape = (attentions.size(0), attentions.size(1), -1) if layerwise else (attentions.size(0) * attentions.size(1), -1)\n",
    "        attentions = _combineTokensByWords(attentions, wordsToTokens)\n",
    "        assert((abs(attentions.sum(axis = -1) - 1) < 0.1).all())\n",
    "        if reshape:\n",
    "          attentions = attentions.reshape(*shape)\n",
    "    else:\n",
    "        if reshape:\n",
    "          attentions = attentions.reshape(attentions.size(0) * attentions.size(1), -1, attentions.size(-1))\n",
    "    if not reshape:\n",
    "        attentions = torch.squeeze(attentions)\n",
    "    return attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:52:50.949397Z",
     "start_time": "2020-08-11T18:52:50.939546Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mAkZw1Jn5lxp"
   },
   "outputs": [],
   "source": [
    "def _combineTokensByWords(attentions, wordsToTokens): # Both rows & columns\n",
    "        nTokens = sum(wordsToTokens)\n",
    "        nWords = len(wordsToTokens)\n",
    "        s = np.zeros((nTokens, nWords))\n",
    "        weights = sum([[1./a] * a for a in wordsToTokens], [])\n",
    "        wordNum = sum([[i]*a for i, a in enumerate(wordsToTokens)], [])\n",
    "        s[list(range(nTokens)), wordNum] = weights\n",
    "        s = torch.FloatTensor(s)\n",
    "        return s.T @ attentions @ s\n",
    "\n",
    "def _wordsToTokensByOffset(sent, offsets): # Not gonna document this \n",
    "    wordOffsets = [-1]+list(map(lambda x: x.span()[0], (re.finditer(r'\\s+', sent))))+[len(sent)+1]\n",
    "    offsets = list(map(lambda x: x[0], offsets)) \n",
    "    zWords = list(zip(wordOffsets, itertools.repeat(\"word\")))\n",
    "    zTokens = list(zip(offsets, itertools.repeat(\"token\")))\n",
    "    s = sorted(itertools.chain(zWords, zTokens), key = lambda x: x[0])\n",
    "    lensArr = np.diff([i for i, a in enumerate(s) if a[1] == 'word'])-1\n",
    "    return lensArr\n",
    "\n",
    "\n",
    "def tokenizeSentencesNoPadding(tokenizers, sentences):\n",
    "    output = []\n",
    "    modelsWordsToTokens = []\n",
    "    for tokenizer in tokenizers:\n",
    "        output += [[]]\n",
    "        modelsWordsToTokens += [[]]\n",
    "        print(tokenizer.__class__)\n",
    "        for sent in tqdm(sentences):\n",
    "            tokenized_sent = tokenizer(sent, pad_to_max_length = False, max_length=60, return_tensors='pt', \n",
    "                                       return_offsets_mapping = True,\n",
    "                                       truncation = True)\n",
    "            \n",
    "            tokenOffsets = (tokenized_sent.pop('offset_mapping').numpy()[0]).tolist() #TODO: Make sure the 0-index does the right thing\n",
    "            modelsWordsToTokens[-1]+=[ _wordsToTokensByOffset(sent, tokenOffsets) ]\n",
    "            output[-1]+=[ tokenized_sent]\n",
    "    return zip(output, modelsWordsToTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:53:21.643478Z",
     "start_time": "2020-08-11T18:52:52.364863Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "NRgaPczi5lxs",
    "outputId": "0ac4a6e0-1fa0-4586-b7c6-946621004b9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:00<00:00, 176.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_bert.BertTokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 414.74it/s]\n",
      " 16%|█▌        | 16/100 [00:00<00:00, 154.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_gpt2.GPT2TokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 268.16it/s]\n",
      " 22%|██▏       | 22/100 [00:00<00:00, 186.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_roberta.RobertaTokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 233.79it/s]\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 100\n",
    "((bertEncoded, bertWordsToTokens), \n",
    "     (gptEncoded, gptWordsToTokens), \n",
    "     (robertaEncoded, robertaWordsToTokens)) = tokenizeSentencesNoPadding((bertTokenizer, gptTokenizer, robertaTokenizer),\n",
    "                                                                       sentences[:num_sentences])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T18:28:24.619415Z",
     "start_time": "2020-08-10T18:28:24.614388Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Iyjjm5d-5lx0"
   },
   "outputs": [],
   "source": [
    "def headSimilarityNoPadding(modelA, modelB, encodedA_list, encodedB_list, \n",
    "                                           wordsToTokensA_list, wordsToTokensB_list):\n",
    "    res = None\n",
    "    for (encodedA, encodedB, wordsToTokensA, wordsToTokensB) in tqdm(\n",
    "                                        zip(encodedA_list, encodedB_list,\n",
    "                                          wordsToTokensA_list, wordsToTokensB_list), total = len(encodedA_list)):\n",
    "\n",
    "        N = len(wordsToTokensA) # TODO: Fix N to the right formula\n",
    "        attentionsA = _getAttentionsReshaped(modelA(**encodedA), wordsToTokens = wordsToTokensA).detach().numpy()\n",
    "        attentionsB = _getAttentionsReshaped(modelB(**encodedB), wordsToTokens = wordsToTokensB).detach().numpy() \n",
    "        \n",
    "        new_res = klDivAllPairs(attentionsA, attentionsB, N)\n",
    "        if res is None:\n",
    "            res = new_res\n",
    "        else:\n",
    "            res += new_res\n",
    "    \n",
    "    return res/len(encodedA_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwjJpboC5lyR"
   },
   "source": [
    "## Get \"clean\" attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:53:52.018950Z",
     "start_time": "2020-08-11T18:53:52.015621Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "J-pH_9jU5lyR"
   },
   "outputs": [],
   "source": [
    "def cleanseAttentions(att):\n",
    "    att_ = att.clone()\n",
    "    mymax = att.max(axis = -1)[0].unsqueeze(-1)\n",
    "    threshold = mymax * .25\n",
    "    att_[att < threshold] = 0\n",
    "    att_[att >= threshold] = 1\n",
    "    return att_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:54:23.532500Z",
     "start_time": "2020-08-11T18:54:23.529616Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Bor_KUdj5lyT"
   },
   "outputs": [],
   "source": [
    "(modelA, modelB, encodedA_list, encodedB_list, \n",
    "            wordsToTokensA_list, wordsToTokensB_list) = (bertModel, gptModel, bertEncoded, gptEncoded, \n",
    "                                  bertWordsToTokens, gptWordsToTokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LT_xlE8qoNdy"
   },
   "outputs": [],
   "source": [
    "def goodAttention(attentionsA):\n",
    "  return ((attentionsA.topk(5, axis = -1)[0].sum(axis =-1, keepdims = False ) > 0.7)\n",
    "         & (attentionsA.topk(2, axis = -1)[0].sum(axis =-1, keepdims = False ) < 0.7)\n",
    "  ).type('torch.FloatTensor')\n",
    "  # (cleanseAttentions(attentionsA)\n",
    "  #                 .topk(3, axis = -1)[0].sum(axis =-1, keepdims = False ) > 0.5).type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "575e168dc3e342a092436f0c2de9df16",
      "45bd909ed17845a78b6704a2f05867b8",
      "d8e0a1f5957d41d0939c37e966747116",
      "374ad1ad791a4a6a9374b26d64e5f893",
      "0e316a96df4a4bcebdc5843feeaa7079",
      "5cad6ce6fa6249e0a41b864a3544bf75",
      "16b72f333a9b4f8aa15ef5d8b23f4db0",
      "1e2bd499aa854b4b9f31ffbe29408f9d"
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "1l9_v09g5lyU",
    "outputId": "b5e6e6ad-397a-464d-ce11-c99b48422732"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575e168dc3e342a092436f0c2de9df16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "nSamples = len(encodedA_list)\n",
    "s = torch.zeros((24,16))\n",
    "with torch.no_grad():\n",
    "  for (encodedA, wordsToTokensA) in tqdm_notebook(\n",
    "                                          zip(encodedA_list, wordsToTokensA_list), total = len(encodedA_list)):\n",
    "          \n",
    "          N = len(wordsToTokensA) # TODO: Fix N to the right formula\n",
    "          attentionsA = _getAttentionsReshaped(largeBertModel(**encodedA), \n",
    "                                               wordsToTokens = None, \n",
    "                                               reshape = False)\n",
    "          curS = (goodAttention(attentionsA)\n",
    "                  .mean(axis = -1, keepdims = False))\n",
    "          s += curS\n",
    "                  \n",
    "s = s/nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "XAUxBReqKlsO",
    "outputId": "13b6fc02-f06b-4e7f-ea99-24a52a778571"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2a29ccb00>"
      ]
     },
     "execution_count": 207,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAagUlEQVR4nO3df9hcZX3n8fcnCeGnBCGFQhJJxGCl0gsxF9LaKhq0Eb2IXUoF2kUsml2vjWLtinTZZYWultRF13XBikgQVCiCxUeN/FBBXLdgUuVHfgDGCPIESVQo1mKFPM93/zgnZnh8Zs6cmTMz9zl8XrnOlZkzc9/znXkm39zPfe4figjMzGw4Zow6ADOzZxMnXTOzIXLSNTMbIiddM7MhctI1MxsiJ10zsyFy0jUza0PS5ZK2S1rf5nFJ+t+SNku6R9LRRXU66ZqZtXcFsKzD468DFufHCuBjRRU66ZqZtRERtwOPdXjKcuDKyNwB7Cfp4E51zqoywOk8/ZMtnvJmZl3Zbe7z1W8dZXLO7N847D+QtVB3ujQiLi3xcvOAh1vuj+fnftSuwMCTrplZqvIEWybJ9s1J18yaZXJimK+2FVjQcn9+fq6twqQr6bfI+i3mtbzIWERs6jFIM7PBmdgxzFcbA1ZKugZ4GfBERLTtWoCCpCvpvcCpwDXAt/PT84GrJV0TERf2H7OZWXUiJiurS9LVwHHAXEnjwH8HdsteJ/4OWAOcAGwGngTeUlhnp6UdJT0A/HZEPD3l/GxgQ0QsblNuBXnn9CUX/Y+XvvX0U4viMDOr5ELaU+P3dn8hbf6Rfb9eWUXdC5PAIcBDU84fnD82rdbOaY9eMLOhqrClOwhFSfddwNckfY9dwyKeB7wAWDnIwMzMejLcC2mldUy6EXGjpMOBY3jmhbS1EZH2OzOzZ6eat3SJrFf6jiHEMjB7HvIHfdfxi0e+WUEklhJ/L3Zp0mcRwx29UJrH6ZpZs0zWvKVrZlYrde9eMDOrlTpfSDMzqx23dM3MhsgX0szMhsgX0szMhif1KQROumbWLO7THb0qBm03afB4E1Tx80hFv++liu9Vo76b7l4wMxsit3TNzIZo4uni54xQ4W7Akn5L0lJJ+0w532lbYjOz0Zic7P4YgY5JV9I7gS8A7wDWS1re8vAHBhmYmVlPYrL7YwSKWrpvA14aEW8k27Liv0k6K3+s7YrrklZIWidp3WVXXl1NpGZm3Ui8pVvUpzsjIn4OEBEPSjoOuE7SoXRIut45wsxGJvHRC0Ut3W2Sjtp5J0/AbwDmAkcOMjAzs17ExNNdH6NQ1NI9HXjGROaI2AGcLunjA4vKzKxXdR4yFhHjHR77VvXh/LpUJiU0avB4A/jnYW0l3r3gcbpm1ix1bumamdWOW7pmZkPklq6Z2RDt8CLmZmbD45aumdkQuU/XzGyI3NI1Mxsit3T7k8og+BQmaaQQg1ny3NI1Mxsij14wMxuiSHthw8KdI6aSdOUgAjEzq0Sd19OVNDb1FPAqSfsBRMSJgwrMzKwniV9IK2rpzgd+BnwIuCg//qXl9rS8c4SZjUyF2/VIWibpfkmbJZ0zzePPk3SrpO9KukfSCUV1FvXpLgHOAs4F3hMRd0n6RUR8o1Mh7xxhZiMzMVFJNZJmAhcDrwHGgbWSxiJiY8vT/itwbUR8TNIRwBpgYad6i9bTnQQ+LOlz+d/bisqYmY1Udd0LxwCbI2ILgKRrgOVAa9INYN/89hzgkaJKu0qg+WLmJ0t6PVl3g5lZmkokXUkrgBUtpy7Nf1MHmAc83PLYOPCyKVW8D7hZ0juAvYHji16zVKs1Ir4MfLlMmRQ0ZVJBCjFY9fxzrViJyRGtXaE9OhW4IiIukvS7wFWSXpz3EkzLXQVm1igxWdllpK3Agpb78/Nzrc4ElgFExD9K2oNs497t7SotPU7XzCxp1Y3TXQsslrRI0mzgFGDqMNofAksBJL0I2AP4cadK3dI1s2apaPRCROyQtBK4CZgJXB4RGyRdAKyLiDHgL4FPSPoLsotqZ0R0nhLnpGtmzVLh5IiIWEM2DKz13HkttzcCLy9Tp5OumTVL4jPSnHTNrFkSX/DGSdfMmsUtXTOzIapuyNhAPCuSrgefmz2LVDR6YVCeFUnXzJ49wt0LZmZDlHj3QscZaZJeJmnf/Paeks6X9EVJqyTNGU6IZmYlVLie7iAUTQO+HHgyv/0RsqXLVuXnVg8wLjOz3kxG98cIFCXdGRGxc2vNJRHxroj4vxFxPvD8doW8c4SZjcyOie6PESjq010v6S0RsRq4W9KSiFgn6XDg6XaFvHOEmY3MiLoNulXU0n0r8EpJ3weOAP5R0hbgE/ljZmZpSbx7oWi7nieAM/KLaYvy549HxLZhBGdmVlYjhoxFxM+Au3t5gSp2behXKpMj+v0sqngfqeyikcL3IhUpfD9T+V5UIvEhYx6na2bN4qRrZjZEngZsZjY8Fe6RNhBOumbWLE66ZmZD1ITRC2ZmteGWrpnZEDnpmpkNT0y4e2HkUhmIn8Lg8VQmNvQbRwoxVCWFSTON4paumdnweMiYmdkw1TnpSpoNnAI8EhFflXQa8HvAJuDSiGi7vKOZ2Uik3aVb2NJdnT9nL0lvBvYBPg8sBY4B3jzY8MzMyokdaWfdoqR7ZET8jqRZwFbgkIiYkPRpOqw6JmkFsAJAM+cwY8belQVsZtZR2jm3MOnOyLsY9gb2Itsj7TFgd2C3doVad46YNXte2h0sZtYodb+Q9kngPmAmcC7wuXzniGOBawYcm5lZeXVu6UbEhyX9fX77EUlXAscDn4iIbw8jQDOzMure0iUiHmm5/c/AdQONaAoP/E6Pfya7pDDxpkkTRSpR55aumVndxI5RR9CZk66ZNUriO7AXbsFuZlYvkyWOApKWSbpf0mZJ57R5zp9I2ihpg6TPFtXplq6ZNUpVLV1JM4GLgdcA48BaSWMRsbHlOYuBvwJeHhGPSzqwqF63dM2sUWKy+6PAMcDmiNgSEU+RDZNdPuU5bwMujojHASJie1GlTrpm1igxoa4PSSskrWs5VrRUNQ94uOX+eH6u1eHA4ZK+JekOScuK4nP3gpk1SpnuhdbZsz2aBSwGjgPmA7dLOjIfXtu2gJlZY8SkqqpqK7Cg5f78/FyrceDOfMXFH0h6gCwJr21X6cCTbqMGXfcphYH0VUjhZ5pCDJDOThxNiAFgx1NTc1p5FQ4ZWwsslrSILNmeApw25Tk3AKcCqyXNJetu2NKpUrd0zaxRIqpp6UbEDkkrgZvI1p+5PCI2SLoAWBcRY/ljr5W0EZgA3hMRP+1Ur5OumTVKlZMjImINsGbKufNabgfw7vzoipOumTXK5ERlfboD4aRrZo1S4YW0gRjION3WsW+XXXn1IF7CzGxaMamuj1Eo2phyDtkUtzcCBwIBbAe+AFzYbixa69i3p3+yJe3FLc2sUSLxjFPU0r0WeBw4LiL2j4gDgFfl564ddHBmZmWl3tItSroLI2JVRDy680REPBoRq4BDBxuamVl5Eer6GIWiC2kPSTob+FREbAOQdBBwBs+ck2xmloSJmo9eeBNwDvCNliXLtgFjwMndvEC/M11SmXnkLVF2SeGzSCGGlOKwXUbVgu1W0caUjwPvzY9nkPQWYPWA4jIz60mTh4ydX1kUZmYViej+GIWiIWP3tHsIOKj6cMzM+pN6S7eoT/cg4A/Jhoi1EvD/BhKRmVkfJibT3puhKOl+CdgnIu6a+oCk2wYSkZlZH1KfHFF0Ie3MDo9NXVfSzGzkJus8esHMrG5qPWTMzKxuat29UIWmDIJPZSB9v5oyEL8p76MKqfwbSYW7F8zMhqjuoxfMzGol8d4FJ10zaxZ3L5iZDVHqoxc6dn5I2lfS30i6StJpUx67pEM5b9djZiMxWeIYhaKW7mrge8D1wJ9LOgk4LSJ+CRzbrpC36zGzUQnSbukWJd3DIuKk/PYNks4Fvi7pxAHHZWbWkx2Jdy8UJd3dJc2IiEmAiHi/pK3A7cA+A4/OzKykurd0vwi8GvjqzhMRcYWkR4GPdvMCKewckcKkBEhjokgqUvhepCKFz6JJEyxG1VfbraIFb85uc/5GSR8YTEhmZr1LvaXrnSPMrFFqPXrBO0eYWd1MJN7S9c4RZtYoie/W450jzKxZJuvc0vXOEWZWN6nPxvLaC2bWKLUeMmZmVjeTqnH3QgpSmRCQwgD0FGJoklQmBPQbRyrvIxUTow6gQNpLrJuZlTSp7o8ikpZJul/SZknndHjeSZJC0pKiOpNv6ZqZlVHV6AVJM4GLgdcA48BaSWMRsXHK854DnAXc2U29bumaWaNEiaPAMcDmiNgSEU8B1wDLp3neXwOrgH/rJr7SSVfSgWXLmJkNS5nuhdYNF/JjRUtV84CHW+6P5+d+RdLRwIKI+HK38RVNA95/6ing25JeAigiHmtTbgWwAkAz5zBjxt7dxmNm1pcyQ8ZaN1woS9IM4EPAGWXKFfXp/gR4aMq5ecB3yFrnz5+uUOsbmTV7Xupjlc2sQSaqGzG2FVjQcn9+fm6n5wAvBm5TNkztN4ExSSdGxLp2lRZ1L7wHuB84MSIWRcQiYDy/PW3CNTMbpQpXGVsLLJa0SNJs4BRgbOeDEfFERMyNiIURsRC4gyxXtk24UJB0I+Ii4K3AeZI+lF+lc8vVzJJVVdKNiB3ASuAmYBNwbURskHRBP1uWFQ4Zi4hx4OT8RW4B9irzAk3ZLSGVOFKQwoSAVKTwPlL5eaQywaLKLdIiYg2wZsq589o897hu6ux69EJEjAGvAo4HkPSWbsuamQ1L6ouYlxoyFhG/iIj1+V3vHGFmyZkocYyCd44ws0ap+yLm3jnCzGql7ks7eucIM6uVWidd7xxhZnWT+phWrzJmZo1S9z5dM7NaSX0R84En3RQGjzdFKgPY/TPdxZ/nLlW8jx1PbS1+UoHJxDsY3NI1s0ap9YU0M7O6Sbud66RrZg3TuJaupAMi4qeDCMbMrF87lHZbt+PaC5IulDQ3v71E0hbgTkkPSXplh3K/2gJjcvJfKw7ZzKy9CvdIG4iiBW9eHxE/yW9/EHhTRLyAbHfMi9oViohLI2JJRCzxVj1mNkyprzJW1L0wS9KsfDHfPSNiLUBEPCBp98GHZ2ZWTt2HjF0CrJF0IXCjpI8AnwdeDfzaegxmZqOWdsotXnvho5LuBd4OHJ4/fzFwA9le71YzqQzET2FHkaZMbEjls0hF7UcvRMRtwG1Tz+c7R6yuPiQzs95NJN7WLbVzxBTeOcLMklPrC2neOcLM6iYSb+l65wgza5S69+l65wgzq5VaDxnzzhFmVjdpp1wveGNmDbMj8bTrpGtmjVL3C2mWS2HweAoD8ZvEn+cuqXwW1ewckTYnXTNrFLd0zcyGyC1dM7Mhmgi3dM3Mhib1cbpFO0cskXSrpE9LWiDpFklPSFor6SUdynnnCDMbiSjxZxSKFry5BPhb4Mtk034/HhFzgHPyx6blnSPMbFRSX/CmKOnuFhFfiYirgYiI68hufA3YY+DRmZmVNEl0fYxCUdL9N0mvlXQyEJLeCJBvSjkx8OjMzEqqsntB0jJJ90vaLOmcaR5/t6SNku6R9DVJhxbVWXQh7T+SdS9Mkq029nZJVwBbgbcVRtwgqQweN7POqhq9IGkmcDHZRrzjwFpJYxGxseVp3wWWRMSTkt5Oli/f1Kneji3diLg7Iv4wIl4XEfdFxFkRsV9E/Dbwwr7ekZnZAFTYvXAMsDkitkTEU8A1wPLWJ0TErRHxZH73DmB+UaXeOcLMGqXMhbTWkVb5saKlqnnAwy33x/Nz7ZwJfKUoPu8cYWaNUmYoWERcClza72tK+jNgCfDKoud65wgza5QKRyVsBRa03J+fn3sGSccD5wKvjIhfFlXqnSPMrFGiumnAa4HFkhaRJdtTgGds3pBPEvs4sCwitndTqXeOMLNGqWoL9ojYIWklcBMwE7g8IjZIugBYFxFjwAeBfYDPSQL4YUSc2Kler71gZo1S5aSHiFgDrJly7ryW28eXrdNJ18wapcLuhYFw0rWR8GQTG5TUVxlz0jWzRvHOEWZmQ+RFzM3MhsjdC2ZmQ5R60i3aOWKOpAsl3SfpMUk/lbQpP7dfh3LeOcLMRiIiuj5GoWjBm2vJpgAfFxH7R8QBwKvyc9e2K+SdI8xsVOq+iPnCiFgVEY/uPBERj0bEKqBwsV4zs2Gr+x5pD0k6W9KvVhSTdJCk9/LMJc/MzJIwEZNdH6NQdCHtTWSbUH4jT7wBbAPGgD8ZcGxmA/WLR77Zdx2e5JGeWs9Ii4jHJa0GbgHuiIif73xM0jLgxgHHZ2ZWSt1HL7wT+AKwElgvqXWrig8MMjAzs16k3qdb1L3wNuClEfFzSQuB6yQtjIiPkC1kbmaWlMk6dy8AM3Z2KUTEg5KOI0u8h+Kka2YJSn3thaLRC9skHbXzTp6A3wDMBY4cZGBmZr2o++iF04EdrSciYgdwuqSPDywqM7Me1bp7ISLGOzz2rerDMTPrT+rdC17wxswapdYtXdulioH0tksKkwpSiAH6/26l8j5S4ZaumdkQTcTEqEPoyEnXzBql1tOAzczqJvVpwE66ZtYoqbd0i9Ze2FfS30i6StJpUx67pEM57xxhZiMxGdH1MQpFM9JWk033vR44RdL1knbPHzu2XSHvHGFmo1L3BW8Oi4iT8ts3SDoX+LqkEwccl5lZT0Y1vbdbRUl3d0kzIrJ3ERHvl7QVuB3YZ+DRmZmVlHqfblHS/SLwauCrO09ExBWSHgU+OsjAUpPCAHTvdNBM/plUK/UZaR37dCPibGBc0lJJ+7ScvxF456CDMzMrq9ZbsEt6B9nOEe/g13eOeP8gAzMz60XqW7AXdS+swDtHmFmN1L1P1ztHmFmtpD56wTtHmFmjpD45wjtHmFmjpN69UDR6YTwiHm3zmHeOMLPkVDkjTdIySfdL2izpnGke313S3+eP35lf++qoqHvBzKxWqhoyJmkmcDHwOuAI4FRJR0x52pnA4xHxAuDDwKqi+Jx0zaxRKuzTPQbYHBFbIuIp4Bpg+ZTnLAc+ld++DlgqqfMggzL/KwzqAFaMsnyT6kghBr8PfxaDrKPKg2xY7LqWY0XLY38MXNZy/98D/2dK+fXA/Jb73wfmdnrNVFq6K0Zcvkl1pBBDFXWkEEMqdaQQQ0p1VCZaVkTMj0sH/ZqpJF0zs9RsBRa03J+fn5v2OZJmAXOAn3aq1EnXzGx6a4HFkhZJmg2cAoxNec4Y8Ob89h8DX4+8n6GdVLbr6bdJX8WvBE2pI4UYqqgjhRhSqSOFGFKqYygiYoeklcBNwEzg8ojYIOkCYF1EjAGfBK6StBl4jCwxd6SCpGxmZhVy94KZ2RA56ZqZDdFIk27RFLsuyl8uabuk9X3EsEDSrZI2Stog6ayS5feQ9G1Jd+flz+8jlpmSvivpSz2Wf1DSvZLukrSuxzr2k3SdpPskbZL0uyXKvjB/7Z3HzyS9q4cY/iL/LNdLulrSHj3UcVZefkO3MUz3fZK0v6RbJH0v//u5JcufnMcwKWlJjzF8MP953CPpHyTt10Mdf52Xv0vSzZIOKVtHy2N/KSkkzS0Zw/skbW35fpzQKYbGGuGg5JlkA4mfD8wG7gaOKFnHK4CjgfV9xHEwcHR++znAA2XiIFvicp/89m7AncCxPcbybuCzwJd6LP8gBQOzu6jjU8Bb89uzgf36+Pk+Chxastw84AfAnvn9a4EzStbxYrJB63uRXSz+KvCCXr5PwN8C5+S3zwFWlSz/IuCFwG3Akh5jeC0wK7+9qlMMHerYt+X2O4G/K1tHfn4B2YWlhzp919rE8D7gP/fz/WzCMcqWbjdT7DqKiNvJrhj2LCJ+FBHfyW//C7CJ7B9+t+Uj8jWHyZLublB+SXpJ84HXA5eVLVsVSXPI/rF8EiAinoqIf+6xuqXA9yPioR7KzgL2zMc97gU8UrL8i4A7I+LJyFbF+wbw74oKtfk+tU7z/BTwxjLlI2JTRNzfbeBt6rg5fx8Ad5CNFy1bx89a7u5NwXe0w7+tDwNn91H+WW+USXce8HDL/XFKJLtByFcIeglZa7VMuZmS7gK2A7dERKnyuf9F9mXuZwXmAG6W9E+Sepn5swj4MbA67+a4TNLePcZyCnB12UIRsRX4n8APgR8BT0TEzSWrWQ/8gaQDJO0FnMAzB7mXcVBE/Ci//ShwUI/1VOXPga/0UlDS+yU9DPwpcF4P5ZcDWyPi7l5eP7cy7+a4vFNXTZP5QlpO2cab1wPvmtIqKBQRExFxFFkL5BhJLy752m8AtkfEP5UpN43fj4ijyVZF+k+SXlGy/CyyXwk/FhEvAf6V7FfqUvKB5CcCn+uh7HPJWpeLgEOAvSX9WZk6ImIT2a/hNwM3AncBE2VjmabeoIffYqoi6Vyy9a0/00v5iDg3Ihbk5VeWfO29gP9CD8m6xceAw4CjyP5DvaiPumprlEm3myl2QyFpN7KE+5mI+Hyv9eS/it8KLCtZ9OXAiZIeJOtmebWkT/fw+lvzv7cD/0DWhVPGODDe0lK/jiwJl/U64DsRsa2HsscDP4iIH0fE08Dngd8rW0lEfDIiXhoRrwAeJ+ur78U2SQcD5H9v77Gevkg6g2zXlj/Nk38/PgOcVLLMYWT/Ed6df0/nA9+R9JvdVhAR2/IGyiTwCcp/PxthlEm3myl2AydJZH2YmyLiQz2U/42dV5Ml7Qm8BrivTB0R8VcRMT8iFpJ9Dl+PiFKtO0l7S3rOzttkF19KjeqIbMH6hyW9MD+1FNhYpo7cqfTQtZD7IXCspL3yn81Ssn72UiQdmP/9PLL+3M/2GE/rNM83k+2OPVSSlpF1PZ0YEU/2WMfilrvLKf8dvTciDoyIhfn3dJzsAvS0mxy0ieHglrt/RMnvZ2OM8ioeWV/bA2SjGM7tofzVZL+mPE32JTizhzp+n+xXxnvIfg29CzihRPnfAb6bl18PnNfnZ3IcPYxeIBsFcnd+bOjl88zrOYpsibt7gBuA55YsvzfZgh9z+vgMzidLCuuBq4Dde6jjm2T/YdwNLO31+wQcAHwN+B7ZKIj9S5b/o/z2L4FtwE09xLCZ7PrHzu9n0ciD6eq4Pv887wG+CMwrW8eUxx+k8+iF6WK4Crg3j2EMOLiffyt1PTwN2MxsiHwhzcxsiJx0zcyGyEnXzGyInHTNzIbISdfMbIicdM3MhshJ18xsiP4/oSpl5ruzxfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(s < 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "w-ZEcj1TsVHb",
    "outputId": "cdd64686-cac3-4fdf-9320-dbc56034105c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2a0f068d0>"
      ]
     },
     "execution_count": 263,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer =  11\n",
    "head =  10\n",
    "\n",
    "\n",
    "x = attentionsA[layer, head]\n",
    "a = []\n",
    "y = x.topk(3, axis = 0)[1].tolist()\n",
    "for y_ in y:\n",
    "  a+=list(enumerate(y_))\n",
    "\n",
    "z = torch.zeros(*x.shape)\n",
    "for a_ in a:\n",
    "  z[a_] = 1\n",
    "sns.heatmap(z) # Why axis = -1 is not the right one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "cOwDFzoTy5O5",
    "outputId": "cf8724e2-c8a0-47b4-b85f-eddebf731106"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.016917</td>\n",
       "      <td>0.036750</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.982332</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065333</td>\n",
       "      <td>0.980916</td>\n",
       "      <td>0.081167</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>0.982916</td>\n",
       "      <td>0.187833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.013417</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.269583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.730750</td>\n",
       "      <td>0.110750</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.144333</td>\n",
       "      <td>0.698167</td>\n",
       "      <td>0.117833</td>\n",
       "      <td>0.249667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258833</td>\n",
       "      <td>0.210917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>0.445333</td>\n",
       "      <td>0.836583</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216167</td>\n",
       "      <td>0.177667</td>\n",
       "      <td>0.201167</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.466417</td>\n",
       "      <td>0.960083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.511417</td>\n",
       "      <td>0.041583</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.964250</td>\n",
       "      <td>0.535167</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.681583</td>\n",
       "      <td>0.184167</td>\n",
       "      <td>0.811750</td>\n",
       "      <td>0.985999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.980667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274250</td>\n",
       "      <td>0.798666</td>\n",
       "      <td>0.162250</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.980666</td>\n",
       "      <td>0.572833</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.875250</td>\n",
       "      <td>0.718917</td>\n",
       "      <td>0.902250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967917</td>\n",
       "      <td>0.922250</td>\n",
       "      <td>0.993666</td>\n",
       "      <td>0.153083</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.999833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.901667</td>\n",
       "      <td>0.992833</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.506333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.780333</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>0.970583</td>\n",
       "      <td>0.999667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.951667</td>\n",
       "      <td>0.358917</td>\n",
       "      <td>0.983166</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.921417</td>\n",
       "      <td>0.990666</td>\n",
       "      <td>0.995500</td>\n",
       "      <td>0.362833</td>\n",
       "      <td>0.086250</td>\n",
       "      <td>0.685250</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.759083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.745583</td>\n",
       "      <td>0.758167</td>\n",
       "      <td>0.423833</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.181167</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.923167</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.130333</td>\n",
       "      <td>0.985999</td>\n",
       "      <td>0.738833</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.780250</td>\n",
       "      <td>0.952667</td>\n",
       "      <td>0.829500</td>\n",
       "      <td>0.589167</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.949500</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.501583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.948250</td>\n",
       "      <td>0.848750</td>\n",
       "      <td>0.304583</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.733750</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.963500</td>\n",
       "      <td>0.469250</td>\n",
       "      <td>0.180333</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.941583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2   ...        9         10        11\n",
       "0   0.000000  0.013750  0.860000  ...  0.009000  0.982332  0.080000\n",
       "1   0.065333  0.980916  0.081167  ...  0.019417  0.370500  0.269583\n",
       "2   1.000000  0.960000  0.730750  ...  1.000000  0.258833  0.210917\n",
       "3   0.979000  0.073250  0.445333  ...  0.999667  0.466417  0.960083\n",
       "4   0.511417  0.041583  0.520833  ...  0.184167  0.811750  0.985999\n",
       "5   0.980667  1.000000  0.274250  ...  0.999833  0.997500  0.969000\n",
       "6   0.875250  0.718917  0.902250  ...  0.990000  0.984000  0.999833\n",
       "7   0.764000  0.901667  0.992833  ...  0.983000  0.970583  0.999667\n",
       "8   0.951667  0.358917  0.983166  ...  0.685250  0.828667  0.759083\n",
       "9   0.745583  0.758167  0.423833  ...  0.832833  0.416667  0.202500\n",
       "10  0.130333  0.985999  0.738833  ...  0.949500  0.910000  0.501583\n",
       "11  0.948250  0.848750  0.304583  ...  0.180333  0.869333  0.941583\n",
       "\n",
       "[12 rows x 12 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "9zpJWeskntzZ",
    "outputId": "69a5666c-b64f-4d78-ebf3-4fc5c46fd6e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2a4163c18>"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(s.numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynJiy0nR5lyY"
   },
   "source": [
    "### With padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Nv8Ew6JV5lyZ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bertTokenizerFast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-750ef19081f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbertEncoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_to_max_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgptEncoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgptTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_to_max_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrobertaEncoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_to_max_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bertTokenizerFast' is not defined"
     ]
    }
   ],
   "source": [
    "num_sentences = 4000\n",
    "bertEncoded = bertTokenizerFast.batch_encode_plus(sentences[:num_sentences],pad_to_max_length = True, max_length=512, return_tensors='pt', truncation=True).to(device)\n",
    "gptEncoded = gptTokenizerFast.batch_encode_plus(sentences[:num_sentences],pad_to_max_length = True,  max_length=512, return_tensors='pt', truncation=True).to(device)\n",
    "robertaEncoded = robertaTokenizer.batch_encode_plus(sentences[:num_sentences],pad_to_max_length = True, max_length=512, return_tensors='pt', truncation=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzzIFwjj5lyc"
   },
   "source": [
    "#### Check encoding alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "OFHg2-405lyd",
    "outputId": "f89b7c1c-d39b-40cc-b696-efd725938798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "print(len(bertTokenizer.encode(sentences[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZMoxeKJP5lyh"
   },
   "outputs": [],
   "source": [
    "a = list(map(lambda x: len(x[1])-len(x[0]), zip(gptEncoded['input_ids'], bertEncoded['input_ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5tY-FN5I5lyj"
   },
   "outputs": [],
   "source": [
    "def _sliceToBatches(encoded, batch_size):\n",
    "    batches = []\n",
    "    return [{k:v[i*batch_size:(1+i)*batch_size] for k,v in encoded.items()} \n",
    "                                    for i in range(int(np.ceil(len(encoded['input_ids'])/batch_size)))]\n",
    "\n",
    "def headSimilarityWithPadding(modelA, modelB, encodedA_list, encodedB_list):\n",
    "    res = None\n",
    "    for encodedA, encodedB in tqdm(zip(encodedA_list, encodedB_list), total = len(encodedA_list)):\n",
    "        N = len(encodedA['input_ids'][0])\n",
    "        attentionsA = _getAttentionsReshaped(modelA(**encodedA))\n",
    "        attentionsB = _getAttentionsReshaped(modelB(**encodedB)) # ( nLayers * nHeads, batch * N * N)\n",
    "        denom = attentionsA.size(1) / N\n",
    "        new_res = ((attentionsA @ attentionsB.transpose(0, 1))/denom).detach().numpy()\n",
    "        if res is None:\n",
    "            res=new_res\n",
    "        else:\n",
    "            res+=new_res\n",
    "    \n",
    "    return res/len(encodedA_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mMmetqT75lyn"
   },
   "outputs": [],
   "source": [
    "sim_mat = headSimilarityWithPadding(robertaModel, bertModel,_sliceToBatches(robertaEncoded, 10), _sliceToBatches(bertEncoded, 10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWg2PzmF5lyK"
   },
   "source": [
    "## Predict Attention Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T18:49:35.365055Z",
     "start_time": "2020-08-10T18:49:35.362188Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7RPeQDf45lyL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "88dc2ba072974a9187389fe2af3d2012",
      "318357c2a0b24bc98763b93ba9032636",
      "e41e3d84c003421bac6a0afa82c4300e",
      "3376dc3b87fc418f8ab0e4547cb992fb",
      "9e9dab99dba646839e5450def9ebd453",
      "f85fa4aa2f734a72acb8992539bdd089",
      "dc841261a32a44cba6ba8c08fd4d56dd",
      "1de3d9f0dd6e478da539fa81298c3b84",
      "cf16150fc7d14066807605a36e4bfdab",
      "8a431d69834f490388ac15f401274cc8",
      "cc2bcbbae5c34880a6469733598fd187",
      "26c8f6a7bf2048c5ae8b8cfb10b5f7d5",
      "b578804a78a044ce85f6b5febff7bc9a",
      "8802e88f3c004e1ab23979b279deb832",
      "7763205de9874472a1d884153e77d359",
      "27bb1801879145eab963c9a22aba747f",
      "dd2275ce3fb040fabb05b9898a27fa5a",
      "a54ba335b91d446e863a31faf2874953",
      "a69e626df9d5401ab54c024ec73cde64",
      "c6461e5536254c17bf94a849d67268ca",
      "c5e4644028b74d0996a6a2c4c8d080c0",
      "7c2834261f024e67ac3f0cd8702b6c17",
      "c336af7f3dd544f491edb29cc237f081",
      "79be731212994afb9f4a46d4a7c244c9"
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "9eompz7NxXC0",
    "outputId": "a2b1c655-3bb3-4316-dfa2-b92f8b3d6070"
   },
   "outputs": [],
   "source": [
    "largeBertTokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased', output_attentions = True,  cache_dir = cache_dir)\n",
    "largeBertModel = AutoModel.from_pretrained('bert-large-uncased', output_attentions = True, cache_dir = cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _getSentLen(sent):\n",
    "  assert(len(sent.shape) == 1)\n",
    "  a = np.where(np.isnan(sent))[0]\n",
    "  if len(a) == 0:\n",
    "    return (sent.shape[0])\n",
    "  else:\n",
    "    return a[0]\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T18:50:13.397980Z",
     "start_time": "2020-08-10T18:49:13.512Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "4xh88-4o5lyP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-86b3a2a9c14b>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(enumerate(encodedA_list))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f88f944cc549d9a174264e61db546c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_sent_len = 60\n",
    "inputs_memmap = np.memmap(guy_folder + \"/inputs.memmap\", dtype = 'float32', shape = (100, 12, 12, max_sent_len, max_sent_len), mode = \"w+\")\n",
    "target_memmap = np.memmap(guy_folder + \"/target.memmap\", dtype = 'float32', shape = (100, max_sent_len, max_sent_len), mode = \"w+\")\n",
    "\n",
    "inputs_memmap[:] = None\n",
    "target_memmap[:] = None\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "t = tqdm_notebook(enumerate(encodedA_list))\n",
    "for i, encodedA in t:\n",
    "        inputs = _getAttentionsReshaped(bertModel(**encodedA), wordsToTokens = None, reshape = False).detach().numpy()\n",
    "        target = _getAttentionsReshaped(largeBertModel(**encodedA), wordsToTokens = None, reshape = False)[10, 0].detach().numpy()\n",
    "        \n",
    "        sent_len = target.shape[0]\n",
    "        inputs_memmap[i, :, :, :sent_len, :sent_len] = inputs\n",
    "        target_memmap[i, :sent_len, :sent_len] = target\n",
    "\n",
    "\n",
    "\n",
    "inputs_memmap.flush()\n",
    "target_memmap.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T18:50:04.829422Z",
     "start_time": "2020-08-10T18:50:04.824480Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "HuUdGkgm5lyN"
   },
   "outputs": [],
   "source": [
    "class AttentionCombiner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionCombiner, self).__init__()\n",
    "        self.n_heads = self.n_layers = 12\n",
    "        self.n_total_heads = self.n_heads * self.n_layers\n",
    "        self.weight = nn.Parameter(torch.ones((self.n_total_heads,1, 1))/100)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(self.n_total_heads, x.size(2), x.size(3))\n",
    "        w = F.softmax(self.weight)\n",
    "        # w /= w.sum(axis = 0, keepdims = True)\n",
    "        x = (w * x).sum(axis = 0)\n",
    "        return x #F.softmax(x, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionConverter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionConverter, self).__init__()\n",
    "        self.combiner = AttentionCombiner()\n",
    "        self.cnn = nn.Conv1d(1, 1, 3, padding = 1)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.cnn.weight)\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        x = self.cnn(x.view(-1, 1, x.size(-1)))\n",
    "        x = x.view(*shape)\n",
    "        x = self.combiner(x)\n",
    "        return F.softmax(x.view(x.size(-1), x.size(-1)), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]<ipython-input-83-86b061a03448>:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  w = F.softmax(self.weight)\n",
      "  2%|▏         | 2/100 [00:00<00:09, 10.05it/s, Loss: 0.7369477272033692]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.37it/s, Loss: 0.5626647146961006]\n",
      "  1%|          | 1/100 [00:00<00:16,  6.09it/s, Loss: 0.5574845884044832]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.98it/s, Loss: 0.5597491644467759]\n",
      "  3%|▎         | 3/100 [00:00<00:03, 26.88it/s, Loss: 0.5507944445590733]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.51it/s, Loss: 0.5532592730270723]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss: 0.5479231453656708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.28it/s, Loss: 0.5568424806796712]\n",
      "  1%|          | 1/100 [00:00<00:11,  8.35it/s, Loss: 0.5475673899141342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.85it/s, Loss: 0.5736961430884732]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss: 0.5682125854739016]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.10it/s, Loss: 0.563281676072879]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss: 0.5497624980293542]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.25it/s, Loss: 0.564752683173536]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-01.\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.21it/s, Loss: 0.5557776252523241]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss: 0.5510568442037124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.43it/s, Loss: 0.5575514441152277]\n",
      "  2%|▏         | 2/100 [00:00<00:06, 15.25it/s, Loss: 0.5434966996569788]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.72it/s, Loss: 0.5567320547470468]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss: 0.5474983564940133]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.00it/s, Loss: 0.5585986844613839]\n",
      "  3%|▎         | 3/100 [00:00<00:04, 20.88it/s, Loss: 0.5449971921985703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    11: reducing learning rate of group 0 to 2.5000e-01.\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [00:14<00:06,  3.42it/s, Loss: 0.543146003252798] "
     ]
    }
   ],
   "source": [
    "\n",
    "attConv = AttentionConverter()\n",
    "optimizer = torch.optim.Adam(attConv.parameters(), lr = 1)\n",
    "criterion = nn.KLDivLoss(reduction = 'batchmean')\n",
    "avg_loss = None\n",
    "beta = 0.95\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5, patience = 3, \n",
    "                                                       threshold = 1e-2,\n",
    "                                                       min_lr = 1e-4,\n",
    "                                                      verbose = True)\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"Epoch \" + str(i))\n",
    "    t = tqdm(encodedA_list)\n",
    "    for i, encodedA in enumerate(t):\n",
    "      attConv.zero_grad()\n",
    "      cur_inputs = inputs_memmap[i]\n",
    "      cur_target = target_memmap[i]\n",
    "\n",
    "      sent_len = _getSentLen(cur_target[0])\n",
    "      inputs = torch.from_numpy(cur_inputs[:,:, :sent_len, :sent_len])\n",
    "      target = torch.from_numpy(cur_target[ :sent_len, :sent_len]) \n",
    "      loss = criterion(torch.log(attConv(inputs)), target)\n",
    "      if not avg_loss:\n",
    "            avg_loss = loss.item()\n",
    "      avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "      t.set_postfix_str(\"Loss: \" + str(avg_loss))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    scheduler.step(avg_loss)\n",
    "    t.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-20c3bd58a35b>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(encodedA_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa13d3f90243400496d4fa2cf2554687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-86b061a03448>:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  w = F.softmax(self.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-20c3bd58a35b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/specific/scratches/scratch/guy/miniconda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(attConv.parameters(), lr = 1e-2)\n",
    "from tqdm import tqdm_notebook\n",
    "criterion = nn.KLDivLoss(reduction = 'batchmean')\n",
    "for i in range(5):\n",
    "  print(\"Epoch \" + str(i))\n",
    "  t = tqdm_notebook(encodedA_list)\n",
    "\n",
    "  for encodedA in t:\n",
    "          attConv.zero_grad()\n",
    "          inputs = _getAttentionsReshaped(bertModel(**encodedA), wordsToTokens = None, reshape = False)\n",
    "          target = _getAttentionsReshaped(largeBertModel(**encodedA), wordsToTokens = None, reshape = False)[10, 0] \n",
    "          shape = target.shape\n",
    "          loss = criterion(torch.log(attConv(inputs)), target)\n",
    "          t.set_postfix_str(\"Loss: \" + str(loss.item()))\n",
    "          loss.backward()\n",
    "          optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "colab": {
   "name": "attentions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "guy-python",
   "language": "python",
   "name": "guy-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "457px",
    "left": "734px",
    "right": "20px",
    "top": "147px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
